{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptions and Implementations of algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steam Games Predictor:** by: Kornel Zieliński, Krystian Rodzaj, Krystian Wojakiewicz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure our algorithms can correctly distinguish our input parameters, we first have to encode them. This process has been explained in the previous presentation. Now, that we have our encoded datasets, we can start implementing the chosen algorithms. For the implementation of our algorithms we will use the **sklearn** Python library, which provides a wide range of machine learning tools. In this presentation we will cover: **Support Vector Machines**, **Linear Regression**, **Decision Trees**. We will look at the different parameter used for building the algorithms, how they were achieved, and what they represent. The results for some of the runs of the algorithms will also be shown. In the future, neural networks will be implemented and compared to the results presented here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see methods used for storing achieved figures (\"save_fig\") and for loading the csv files containing encoded datasets (\"load_data\"). Some useful constants are also set here (paths, folder names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Location, in which the figures will be saved\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"machine_learning_part\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"pictures\", CHAPTER_ID)\n",
    "DATA_PATH = 'E:\\\\PROGRAMS\\\\GitHub\\\\SteamGamesPredictor\\\\src\\\\data_shuffle\\\\data\\\\'\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving image\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resoflution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(steam_path, file):\n",
    "    csv_path = os.path.join(steam_path, file)\n",
    "    return pd.read_csv(csv_path, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam = load_data(DATA_PATH, 'enc_steam.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **head** method of the **Pandas** DataFrame structure, we can look at the first few rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accounting</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation &amp; Modeling</th>\n",
       "      <th>Audio Production</th>\n",
       "      <th>Casual</th>\n",
       "      <th>Design &amp; Illustration</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Early Access</th>\n",
       "      <th>Education</th>\n",
       "      <th>...</th>\n",
       "      <th>Year</th>\n",
       "      <th>English</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Required_Age</th>\n",
       "      <th>Achievements</th>\n",
       "      <th>Average_Playtime</th>\n",
       "      <th>Median_Playtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Owners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17612</td>\n",
       "      <td>317</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>62</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>34</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>184</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "      <td>415</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accounting  Action  Adventure  Animation & Modeling  Audio Production  \\\n",
       "0           0       1          0                     0                 0   \n",
       "1           0       1          0                     0                 0   \n",
       "2           0       1          0                     0                 0   \n",
       "3           0       1          0                     0                 0   \n",
       "4           0       1          0                     0                 0   \n",
       "\n",
       "   Casual  Design & Illustration  Documentary  Early Access  Education  ...  \\\n",
       "0       0                      0            0             0          0  ...   \n",
       "1       0                      0            0             0          0  ...   \n",
       "2       0                      0            0             0          0  ...   \n",
       "3       0                      0            0             0          0  ...   \n",
       "4       0                      0            0             0          0  ...   \n",
       "\n",
       "   Year  English  Developer  Publisher  Required_Age  Achievements  \\\n",
       "0  2000        1          0          0             0             0   \n",
       "1  1999        1          0          0             0             0   \n",
       "2  2003        1          0          0             0             0   \n",
       "3  2001        1          0          0             0             0   \n",
       "4  1999        1          4          0             0             0   \n",
       "\n",
       "   Average_Playtime  Median_Playtime  Rating  Owners  \n",
       "0             17612              317    97.0       0  \n",
       "1               277               62    84.0       1  \n",
       "2               187               34    90.0       1  \n",
       "3               258              184    83.0       1  \n",
       "4               624              415    95.0       1  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_cl = steam.copy()\n",
    "steam_lin = steam.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree learning method is a predictive model commonly used in machine learning and data mining. The idea is based on decision trees, in which the features of the examined subject are represented as the branches, and the target values (output classes) are represented as leaves. The algorithms traverses the tree from the root, making a decision about the given feature at each branch and continuing depending on that decision. When a leaf is reached, the final verdict can be made in terms of the target value residing in that particular leaf. If the target values are a finite set, the tree may be called a classification tree.\n",
    "\n",
    "In our program, we used the **sklearn.tree.DecisionTreeClassifier** class to build our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![decision tree](..\\data\\figures\\dec_tree.png \"Sample decision tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to divide our dataset into one training set and one verification set. The goal for this algorithm is to predict the amount of potential buyers for a new game, based on features like: genre, developers, release date. The **Owners** feature is represented by ranges of owners, e.g. [2000 - 5000]. Thus, we remove the **Owners** feature from our training set and we'll use it for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x,y = steam_cl.loc[:,steam_cl.columns != 'Owners'], steam_cl.loc[:,'Owners']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the process of finding the optimal hyperparameters is shown. We used the **sklearn.model_selection.RandomizedSearchCV** tool with ten iterations to find more suitable hyperparamers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features=None,\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort=False,\n",
       "                                                    random_state=None,\n",
       "                                                    splitter='best'),\n",
       "                   iid='w...\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD63E6D8>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD63E978>,\n",
       "                                        'random_state': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD63EC50>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "param_dist = {\"max_depth\": sp_randint(1,22),\n",
    "              \"max_features\": sp_randint(1, 22),\n",
    "              \"min_samples_split\": sp_randint(2, 100),\n",
    "              \"random_state\": sp_randint(2, 100),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(tree_clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5)\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.720873786407767\n",
      "{'criterion': 'entropy', 'max_depth': 15, 'max_features': 21, 'min_samples_split': 95, 'random_state': 34}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_score_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results of the \"RandomizedSearchCV\".\n",
    "-  **best score**: best prediction rate achieved,\n",
    "-  **best_params**: the parameters, which generated the highest prediction rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features=None,\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort=False,\n",
       "                                                    random_state=None,\n",
       "                                                    splitter='best'),\n",
       "                   iid='w...\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD693048>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD693240>,\n",
       "                                        'random_state': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD6933C8>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {\"max_depth\": sp_randint(10,14),\n",
    "              \"max_features\": sp_randint(8, 12),\n",
    "              \"min_samples_split\": sp_randint(50, 70),\n",
    "              \"random_state\": sp_randint(2, 20),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(tree_clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5)\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7192908400168848\n",
      "{'criterion': 'entropy', 'max_depth': 12, 'max_features': 9, 'min_samples_split': 62, 'random_state': 16}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_score_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'max_depth': [9, 10], 'max_features': [9, 10],\n",
       "                          'min_samples_split': [60, 61, 62, 63, 64, 65, 66],\n",
       "                          'random_state': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                           13, 14, 15, 16, 17, 18, 19]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'max_depth': list(range(9, 11)), 'max_features': list(range(9,11)), 'min_samples_split': list(range(60, 67)), 'random_state': list(range(2, 20))}\n",
    "]\n",
    "grid = GridSearchCV(tree_clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7243035035880118\n",
      "{'max_depth': 9, 'max_features': 10, 'min_samples_split': 61, 'random_state': 11}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "                       max_features=10, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=61,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=11, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
    "                                  max_depth=9, max_features=10, max_leaf_nodes=None,\n",
    "                                  min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                  min_samples_leaf=1, min_samples_split=65,\n",
    "                                  min_weight_fraction_leaf=0.0, presort='auto',\n",
    "                                  random_state=13, splitter='best')\n",
    "\n",
    "\n",
    "tree_clf.fit(x_train,y_train)\n",
    "y_pred = tree_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid overfitting of the model we used a technique called cross validation. This approach doesn't require usage of the validation set. In the technique called k-fold CV (short for cross validation) the training set is splitted into k smaller sets and for each of the k \"folds\" the model is trained using k-1 of the folds as a training set and the remaining fold is used as a validation set. After that the steps are repeated for some other \"validation-fold\" and a training set composed by other folds until every single fold have been used as a validation set. We tried it using 3 or 5 folds. That's why in our project everytime the cross validation method is called the results of it are stored in a three/five element table consisting of accuracy scores or mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.71896252, 0.72079772, 0.71969577])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(tree_clf, x_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7074972300874062\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10506</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26313</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24157</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14372</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>26</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21560</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>29</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18659</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21942</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24272</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21390</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10607</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13887</th>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25695</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14771</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23086</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15533</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16293</th>\n",
       "      <td>26</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted\n",
       "10506     122        122\n",
       "26313     122        122\n",
       "2622       34         45\n",
       "1489       45         45\n",
       "19949     122        122\n",
       "24157     122        122\n",
       "14372     122        122\n",
       "4424      122        122\n",
       "8295       26        122\n",
       "21560     122        122\n",
       "8139       29        122\n",
       "18659     122        122\n",
       "21942     122        122\n",
       "24272     122        122\n",
       "21390     122        122\n",
       "10607     122        122\n",
       "13887      34         26\n",
       "25695     122        122\n",
       "14771     122        122\n",
       "9889      122        122\n",
       "23086     122        122\n",
       "15533     122        122\n",
       "20486     122        122\n",
       "16293      26        122\n",
       "16847     122        122"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests are an example of **ensemble learning**. Ensemble learning is a type of supervised learning and it involves taking multiple trained models, usually from the same base learner, and combining them to improve the prediction rate. The disadvantage is that this method needs significantly more computation than simple **decision trees**. Random forest can intuitively be thought of, as a collection of independent decision trees working together to produce a more accurate prediction.\n",
    "\n",
    "In our, program the **sklearn.ensemble.RandomForestClassifier** is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=10,\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_score=...\n",
       "                   param_distributions={'max_leaf_nodes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD81B4A8>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD81BC88>,\n",
       "                                        'random_state': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD81BF60>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "param_dist = {\"max_leaf_nodes\": sp_randint(2,100),\n",
    "              \"min_samples_split\": sp_randint(2, 100),\n",
    "              \"random_state\": sp_randint(2, 100),\n",
    "              \n",
    "             }\n",
    "# run randomized search\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5)\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272055719712959\n",
      "{'max_leaf_nodes': 71, 'min_samples_split': 3, 'random_state': 93}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_score_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=10,\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_score=...\n",
       "                   param_distributions={'max_leaf_nodes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD7FE5F8>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020EFD7FE400>,\n",
       "                                        'random_state': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020E81F779B0>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {\"max_leaf_nodes\": sp_randint(70,200),\n",
    "              \"min_samples_split\": sp_randint(20, 35),\n",
    "              \"random_state\": sp_randint(50, 100)\n",
    "             }\n",
    "# run randomized search\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, iid=False)\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7298470864939473\n",
      "{'max_leaf_nodes': 133, 'min_samples_split': 32, 'random_state': 52}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_score_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=10,\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_score=...\n",
       "                   param_distributions={'max_leaf_nodes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020E811A50F0>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020E811A5630>,\n",
       "                                        'random_state': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020E811A5A90>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "param_dist = {\"max_leaf_nodes\": sp_randint(170,200),\n",
    "              \"min_samples_split\": sp_randint(20, 36),\n",
    "              \"random_state\": sp_randint(80, 98)\n",
    "             }\n",
    "# run randomized search\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, iid=False)\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7302110836420442\n",
      "{'max_leaf_nodes': 194, 'min_samples_split': 27, 'random_state': 90}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_score_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=9,\n",
       "                                              max_features=10,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=65,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='auto', random_state=13,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'max_leaf_nodes': [184, 185, 186, 187],\n",
       "                          'min_samples_split': [26, 27, 28, 29, 30, 31],\n",
       "                          'random_state': [84, 85, 86, 87]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'max_leaf_nodes': list(range(184, 188)), 'min_samples_split': list(range(26, 32)), \n",
    "               'random_state': list(range(84, 88))\n",
    "             }]\n",
    "grid = GridSearchCV(tree_clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7217180244829042\n",
      "{'max_leaf_nodes': 184, 'min_samples_split': 26, 'random_state': 84}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "                       max_features=10, max_leaf_nodes=184,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=26,\n",
      "                       min_weight_fraction_leaf=0.0, presort='auto',\n",
      "                       random_state=84, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight=None, criterion='gini',\n",
    "                       max_depth=9, max_features=10, max_leaf_nodes=180,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=25,\n",
    "                       min_weight_fraction_leaf=0.0,\n",
    "                       random_state=72, n_estimators=10)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.73414518, 0.72712884, 0.72650927])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf, x_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7137756986335098\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10506</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26313</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24157</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14372</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>26</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21560</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>29</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18659</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21942</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24272</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21390</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10607</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13887</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25695</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14771</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23086</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15533</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16293</th>\n",
       "      <td>26</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted\n",
       "10506     122        122\n",
       "26313     122        122\n",
       "2622       34         29\n",
       "1489       45         45\n",
       "19949     122        122\n",
       "24157     122        122\n",
       "14372     122        122\n",
       "4424      122        122\n",
       "8295       26        122\n",
       "21560     122        122\n",
       "8139       29        122\n",
       "18659     122        122\n",
       "21942     122        122\n",
       "24272     122        122\n",
       "21390     122        122\n",
       "10607     122        122\n",
       "13887      34         34\n",
       "25695     122        122\n",
       "14771     122        122\n",
       "9889      122        122\n",
       "23086     122        122\n",
       "15533     122        122\n",
       "20486     122        122\n",
       "16293      26        122\n",
       "16847     122        122"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A K nearest neighbor algorithm is a data classifier, which estimates probability that a data point is a member of one group or the other depending on the group, in which the nearest data points are located. KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970’s as a non-parametric technique.\n",
    "\n",
    "To use this classifier we used the library sklearn.neighbors.KNeighborsClassifier. We started by looking for the best parameters for our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "                                         25, 26, 27, 28, 29, 30]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "k_range = list(range(15, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7112705783030815\n",
      "{'n_neighbors': 29}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=29, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                           metric_params=None, n_neighbors=29, p=2, weights='uniform')\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the best parameters we used them in the classifier.\n",
    "Used parameters:\n",
    "-\t**algorithm** – Algorithm used to compute the nearest neighbors.\n",
    "-\t**leaf_size** - Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree.\n",
    "-\t**metric** - The distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric.\n",
    "-\t**metric_params** - Additional keyword arguments for the metric function\n",
    "-\t**n_jobs** - The number of parallel jobs to run for neighbors search\n",
    "-\t**n_neighbors** - Number of neighbors to use by default for kneighbors queries\n",
    "-\t**p** - Power parameter for the Minkowski metric\n",
    "-\t**weights** - Weight function used in prediction. We used ‘uniform’ which means that All points in each neighborhood are weighted equally \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian wojakiewicz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.09185773, 0.0873227 , 0.09370359])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, x_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09026444083321022\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be satisfied with chosen parameters. The percentage of correct prediction is 70%, which is a good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION PART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is a machine learning algorithm based on supervised learning. Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x). So, this regression technique finds out a linear relationship between input (x) and output (y). The regression line is the best-fit line for given data. In linear regression, the relationships are modeled using linear predictor functions which estimate model parameters based on data.\n",
    "\n",
    "In this case, we took the ratings column for our output, which is responsible for the overall rating of the game given by players. To use this regressor we used the library sklearn.linear_model.LinearRegression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC LINEAR REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x,y = steam_lin.loc[:,steam_lin.columns != 'Rating'], steam_lin.loc[:,'Rating']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.25,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(x_train, y_train)\n",
    "y_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(regr, x_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=3)\n",
    "regr_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(regr_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most interesting result parameter is the standard deviation. This value is very close to zero, which is a correct result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM REGRESSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines are a very powerful and versatile machine learning algorithms. It can be used in a linear or nonlinear classification tasks, regression tasks or to detect the outliers. It is espescially useful in classification of the complex but not very big datasets. It operates on the principle of finding the widest gap between the separate categories, addition of antoher samples does not affect the margin because it is supported by the samples at the extremities, usually called supporting vectors. SVMs can also be used in regression tasks, this method is called support-vector regression (SVR). In this approach model depends only on subset of the training data, because cost function ignores any training data close to the model prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svm](svm.png \"SVM visualisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "svr_rbf.fit(x_train, y_train)\n",
    "y_pred = svr_rbf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(svr_rbf, x_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=3)\n",
    "svr_rbf_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(svr_rbf_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regr = RandomForestRegressor(ccp_alpha=0.0, max_depth=9, max_features=10, max_leaf_nodes=180,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=25,\n",
    "                       min_weight_fraction_leaf=0.0,\n",
    "                       random_state=72)\n",
    "\n",
    "rf_regr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf_regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf_regr, x_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rf_regr_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(rf_regr_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
